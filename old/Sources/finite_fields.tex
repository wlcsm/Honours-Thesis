% My study of Basis mostly came from https://arxiv.org/ftp/arxiv/papers/1304/1304.0420.pdf
\chapter{Finite Fields}\label{finite-fields}

In this section we will look at performing polynomial multiplication where the coefficients are in a finite field and the polynomial is perhaps in a quotient ring.\\

Some common reasons to use a finite field are:
\begin{itemize}
\item Your problem is naturally stated for polynomials with coefficents
in a finite field. Thus $p^n$ can be anything and we need to be as generic as possible.
\item You are using it to control the error that would arise if you used a complex FFT instead. In this case we perform the calculation over several finite fields and use the Chinese Remainder Theorem to reconstruct the final result. This allows us to have some control over the primes that we choose. (It is actually quite common to use integer rings as well as prime fields).
\item You just need a finite field, such as the Ring Learning with Errors problems. This gives us the most flexibility over the choice of prime field and so we can choose ones which are very efficient to perform arithmetic in using a computer.
\end{itemize}

It is important to differentiate the use cases as each imposes a different set of restriction on the finite fields we can use. The most favourable to implement are of course, those where arithmetic is easily implemented in. This correlates to field fields whose characteristic's binary representation has few ones or that admit very nice optimal normal bases (I haven't covered normal bases yet though).

Remember that one can still use the Karatsuba/Toom-Cook algorithm here as well.

In this section we will cover the Number Theoretic Transform (NTT) which is a generalisation of the Fast Fourier Transform for integer rings. 

\section{Number Theoretic Transform}
\label{sec:ntt}

Say we want to take the DFT of a sequence of coefficients of length $m$ in an integer ring $\Z/N$.

In this we look at the Fast Fourier Transform analogue for integer rings. From our previous explanation of the FFT, we showed that the algorithm is based around the existence of roots of unity. Hence we simply must find such a root in a given finite field.

For such an element $\alpha \in \Z/N$ to be a root of unity of order $m$ it must divide $N - 1$ (the order of the multiplicative group of $\Z/N$) and $\alpha^{N/p} \neq 1$ for all $p | N$. We also need $N$ to be invertible and so $N$ and $n$ should be coprime. This can be summarised in the theorem below

\begin{theorem}
  An $N^\th$ root of unity exists in $GF(F)$ if and only if $N$ divides $\gcd(p_1 - 1, \ldots, p_n - 1)$.
\end{theorem}


\subsection{Rader Transform}
\label{subsec:rt}

\begin{theorem}\label{rader-tranform}
    Suppose that $N$ is prime, then there exists a primitive element for $GF^\times(N)$, that is, a $g \in GF(N)$ such that $\{g^i\}_{i=1}^{N-1}$ generates is a permutation of $1, \ldots, N-1$. Then we consider the DFT under this permutation
    \begin{align*}
      A_k - a_0 = \sum^{n-1}_{i=1} a_i \omega_N^{ik} \qquad &\mapsto \qquad A_{g^k} - a_0 = \sum^{n-1}_{i=1} a_{g^i}\omega_n^{g^{i+k}}\\
      \tx{ via } i \mapsto g^i&, k \mapsto g^k
    \end{align*}
    This can then be realised as the convolution of the two sequences $\{a_{g^i}\}_{i=1}^{n-1}$ and $\omega_N^{g^i}$. Thus from Stockham (\cite{stockham}) the sum can be calculated as
    \[
      \sum^{n-1}_{i=1} a_{g^i}\omega_n^{g^{i+k}} = \tx{DFT}^{-1}\{\tx{DFT}\{a_{g^{-i}}\}\cdot \tx{DFT}\{\omega_N^{g^i}\}\}
    \]
\end{theorem}
% Stockham-DFT-for-Convolutions
Hence this is good if $N - 1$ is highly composite because then we can apply normal FFT algorithms.

From this we can then see that our ideal case is where $N = 2^n + 1$ for some $n$ and where $N$ is prime. This leads us to our use of Fermat numbers in the next section.

\section{Use case: Z to Fp}\label{sec:Z-Fp}

In this section we look at a popular technique for controlling rounding error that can occur with complex FFTs. If we need to perform the Fourier transform on a polynomial in $\Z$ then as we have shown previously, we can lift the polynomial to $\C$ and apply the complex transform. This can cause a problem with very large transforms as we loose precision in the floating point representation of complex numbers. A common technique to combat this is to lift the polynomials in a finite field to then apply the fast Fourier transform.

But if the numbers are large then this will cause a precision error, some paper (FFT-Error-Bound in my computer) said that its about $n / 2$ bits of precision lost for a $2^n$ transform. 

To control the size of the coefficients throughout the process, we can multiply the polynomials via a FFT in several finite fields of relatively small coefficient sizes, and then reconstruct the result in $\Z[x]$ by means of the Chinese Remainder Theorem (CRT).
\[
    \frac{\Z[x]}{M\Z} \cong \frac{\Z[x]}{p_1\Z} \times \cdots \times \frac{\Z[x]}{p_n\Z}
\]
where $M = p_1 \ldots p_n$ where $\{p_i\}_{i=1}^n$ are coprime and where $M$ is greater that the absolute value of the coefficients in the resulting polynomial. It then follows that $M > 2nB^2$ where all the coefficients of the input polynomials are bounded by $B$. $nB^2$ is a bound for the absolute size of the resulting coefficients, and then the 2 is there to take into account the fact that the coefficients can be positive or negative.

From\footnote{A. Fog. Instruction tables: lists of instruction latencies, throughputs and micro- operation breakdowns for intel, AMD and VIA CPUs, 2017. http://www.agner. org/optimize/} we can see that in general, divisions are not optimised in common CPU's and are thus an expensive operation, operating proportional to the length of the operands. To remedy this in a CPU, we can use Montgomery multiplication\footnote{P. Montgomery. Modular multiplication without trial division. Mathematics of Computation, 44(170):519â€“521, 1985.} or Barret Reduction.


\subsection{Fermat Transforms}
\label{subsec:fermat-transforms}

We now look at finding a suitable $N$ such that the NTT in $GF(N)$ can be performed efficiently. As outlined in \cite{intro-to-fmt} this requirement can be formulated into three criteria
\begin{itemize}
\item The transform length $T$, is highly composite to facilitate FFT-like algorithms.
\item Multiplication by the roots of unity are efficient to implement. This corresponds to having a small number of ones in the binary representation
\item Dividing by $N$ is efficient. Also corresponds to a small number of ones in the binary representation.
\end{itemize}

Introduce a theorem
% from Intro-to-FMT
\begin{theorem}\label{thm:fmt-transform-length}
    An $N \times N$ transform $T$ having the cyclic convolution property in the ring of integers modulo an integer $F$ exists if and only if $N$ divides $\gcd(p_1 - 1, \ldots, p_n - 1)$
\end{theorem}

Looking at the last requirement on our list at the beginning of the section, if we were to take $N$ to be a power of two, then by Theorem \ref{thm:fmt-transform-length}, the maximum transform length would be $1$. In keeping in line with that requirement the next would be to consider $2^k - 1$  for some $k \in \N$ (this doesn't have a small number of ones but it would still be efficient to implement). Numbers of this form are known as a Mersenne numbers and their corresponding transforms are Mersenne Number Transforms (MNT). The next we consider is $2^k + 1$, it can then be shown that when $k$ itself is a power of two, it has less small divisors e.g. If $k$ is odd then $3$ divides $2^k + 1$ hence the maximum transform length is $2$. Numbers of the form $2^{2^\ell} + 1$ are known as Fermat Numbers and their corresponding transforms are Fermat Number Transforms (FMT).\\

In fact the Fermat Numbers up to $\ell = 4$ are all primes and so they can be calculated very efficiently using the Rader Transform \ref{rader-transform}. It can then be shown (in the same paper) that all the factors of Fermat numbers are of the form $c2^{\ell + 2} + 1$ for $c \in \N$. Therefore by Theorem \ref{thm:fmt-transform-length} the maximum transform length is $2^{\ell + 2}$. It can also be shown that a root of such order is $2^{2^{t-2}}(2^{2^{t-1}} - 1)$.\\

A downside with this representation is that it requires the representation of $2^k + 1$ bits, so in a computer we would need $2^{k+1}$ bits to represent it. This is therefore not ideal in terms of memory efficiency. Some authors suggest just forgetting about it and rounding a $-1$ to $0$ or $-2$ because there is a low probability ($2^{-k}$ chance) that the number will arise. This of course somewhat defeats the purpose of this technique if your goal was to eliminate all error. Although if you were doing this to reduce intermediate expression swell then this is still valid.\\


\section{Normal Bases}
They are used to make calculations faster, there are both hardware and software designs that arise from normal bases.

Definition from the Normal bases thesis.
A normal basis of $\mathbb{F}_{q^n}$ over $\mathbb{F}_q$ is thus of the form: $\{\alpha,\alpha^q,\ldots ,\alpha^{q^{n-1}}\}$ for some $\alpha \in \F_{q^n}$.


\section{Asymptotic Bounds}

It was shown by Harvey and van der Hoeven \cite{nlogn} that integer multiplication could be performed in $O(n\log n)$ time as we discussed in a previous section. They also presented a conditional algorithm which relied on a unproven but very likely hypothesis, their original algorithm could not be easily adapted for the case of finite field but their conditional one could be and they discuss in more in \cite{ffnlogn}.\\
In this, multidimensional FFTs are used to achieve better complexity under the assumption a suitable distribution of primes. This distribution is widely believed to hold but it remains unproven.

The key step to converting the DFT to a multidimensional DFT is the following isomorphism.
\begin{equation}\label{eq:here}
    R[x_1, \ldots, x_{d-1}] / (x_1^{t_1} - 1, \ldots, x_{d-1}^{t_{d-1}} - 1), \qquad R := \C[y]/(y^r + 1)
\end{equation}

TODO The paper gives an overviews of the integer multiplication scheme and then say "some modification are made to generalise to the case of polynomial multiplication" but then don't precisely say what they are, they just promise they make them in the proof of the main theorem later. So what follows is the overview for integer multiplication with a small notes about some of the changes made at the end, I eventually need to rewrite this to explain the polynomial case directly.
\medskip

% Taken directly from the paper page 5
Under the assumption of the suitable prime distribution, we chose primes $s_1, \ldots, s_d$ such that $s_i = 1 \;(\tx{mod } r)$, where $r$ is a power of two, and where the $s_i$ are not much larger than $r$. We then use a multi-dimensional generalisation of Rader's Algorithm to reduce the DFT of size $s_1 \times \cdots \times s_d$ to a multiplication problem in the ring $\C[x_1, \ldots, x_d] / (x_1^{s_1 - 1} - 1, \ldots, x_d^{s_d - 1} - 1)$, where we write $s_i - 1 = q_i r$ where the $q_i$ are suitably small, we may then reduce this to a collection of complex DFTs of size $q_1 \times \cdots \times q_d$, plus a collection of multiplication problems in $\C[x_1, \ldots, x_d] / (x_1^r - 1, \ldots, x_d^r - 1)$. \\
Replacing $x_d$ with $e^{\pi i / r}y$ see that the latter products are of the form of \ref{eq:here}.  We can then reduce the product to a collection of pointwise products in $R = \C[y] / (y^r + 1)$. These in turn are converted to integer multiplication problems via Kronecker substitution and then handled recursively.

As one may have guessed, the trick is in obtaining the prime $s_1, \ldots, s_d$. To formalise this, take 
\[
    P(a, m) := \min\{q > 0\;:\; q \tx{ is prime and } q = a \;(\tx{mod } m\}
\]
and let $P(m) := \max_a P(a, m)$. Then Linnik's theorem states that there exists an absolute constant $L > 1$ such that $P(m) = O(m^L)$. The current best value is $L = 5.18$ (reference here), and under the Generalised Riemann Hypothesis we can take any $L > 2$. It is shown \cite{ffnlogn} that if $L < 1 + 1/303$ and if $d \sim 10^6$, then the cost of the auxiliary DFTs can be controlled and one does obtain the $O(n \log n)$ bound. It is widely believed that this holds for any $L > 1$.

% This is all taken from 1.2.1 of the n log n paper
To establish the bounds for integer multiplication, we reduce integer multiplication to the computation of multivariate cyclic convolutions in a suitable algebra of the form
\begin{align*}
    \M{R} &= \mathbb{A}[x_1, \ldots, x_d] / (x_1^{p_1} - 1, \ldots, x_d^{p_d} - 1)\\
    \mathbb{A} &= (\Z / m\Z)[u] / (u^s + 1)
\end{align*}

Where $s$ is a power of two and $p_1, \ldots, p_d$ are the first $d$ prime numbers in the arithmetic progression $\ell + 1, 3\ell + 1, 5\ell + 1, \ldots$ where $\ell$ is another power of two with $s^{1/3} \leq \ell \leq s^{2/3}$.  Setting $v = \lcm(\ell^3, p1 - 1, \ldots, p_d - 1)p_1\dots p_d$, we choose $m$ such that there exists a principal $v$-th root of unity in $\Z/m\Z$ that makes it possible to compute products in the algebra $\M{R}$ using FFT algorithms. It is shown that we may in fact take $d = O(1)$, although larger dimensions may allows for speed ups by a constant factor as long as $\lcm(\ell^3, p_1 - 1, \ldots, p_d - 1)$ can be kept small.

Using multivariate Rader transforms the DFTs in $\M{R}$ reduce to the computation of multivariate cyclic convolutions in the algebra
\[
    \M{S} = \A[z_1, \ldots, _d] / (z_1^{p_1 - 1} - 1, \ldots, z_d^{p_d - 1} - 1).
\]
by construction we may factor $p_i - 1 = \ell q_i$, where $q_i$ is a small odd number by our choice of $s_i$. Since $q_i | v$ we have $\Z /mZ$ contains a primitive $q_i$-th root of unity. CRT transforms allow us to rewrite the algebra $\M{S}$ as

\begin{align*}
    \M{S} \cong \mathbb{B}[y_1, \ldots, y_d]/(y_1^\ell - 1, \ldots,s y_d^\ell - 1)\\
    \mathbb{B} = \mathbb{A}[v_1, \ldots, v_d] / (v_1^{q_1} - 1, \ldots, v_d^{q_d} - 1).
\end{align*}
(I think but am not certain this is) because $\gcd(q_1, \ldots, q_n)$ and $\ell$ are coprime.

The most important observation is that $u$ is a "fast" principal $(2s)$-th root of unity in both $\A$ and $\mathbb{B}$. This means that the products in $\M{s}$ can be computed using multivariate Fourier multiplication with the special property that the discrete Fourier transforms become Nussbaumer polynomial transforms. Since $s$ is a power of two, these transforms can be computed in time $O(n \log n)$. For sufficient small Linnik constants $L$, the cost of the "inner multiplications" in $\mathbb{B}$ only marginally contributes to the overall cost. Notice that this is along the same lines as the Schonage Strassen integer multiplication scheme.

There are then some modifications made to generalise this to the polynomial case. In previous arguments we showed that it is sufficient to consider the case $\F_p$ where $p$ is prime (rather than a power of a prime). In particular we define, $\A = \F_{p^k}[u] / (u^s + 1)$, with $k = \lcm(p_1 - 1, \ldots, p_d - 1)$, which ensures the existence of primitive ($p_1 \ldots p_d$)-th roots of unity in $\F_{p^k}$ and hence $\A$.

However this creates further complications since, multiplications in $\F_{p^k}$ take exponentially longer than those in $\F_p$, for this reason we additionally require that $q_1, \ldots, q_d$ be pairwise coprime. This allows us to reduce multiplications in $\mathbb{B}$ to univariate multiplications in $\A[v]/(v^{q_1\cdots q_d} - 1)$. As is later shown, this comes at the addition cost of requiring $L < 1 + 2^{-1162}$ on $L$.

\section{Multi-dimensional Variant of Rader's trick}%
\label{sec:multi_dimensional_variant_of_rader_s_trick}

\subsection{The DFT as a Tensor Product}%
\label{sub:the_dft_as_a_tensor_product}



In the previous section we stated that we can perform a multivariate analogue to the Rader transform in the ring $R[x_1, \ldots, x_{d-1}] / (x_1^{t_1} - 1, \ldots, x_{d-1}^{t_{d-1}} - 1)$. To see this, we recall that multivariate Fourier transform can be interpreted as a tensor product of univariate Fourier transforms. To then compute the tensor 

% Brief introduction of tensors takes almost word for word from the source (ffnlogn)
Let $R$ be a commutative ring and let $A$ and $B$ be two $R$-modules. Then the \emph{tensor product} $A \otimes B$ of $A$ and $B$ is an $R$-module together with a bilinear mapping $\otimes A \times B \to A \otimes B$ which satisfies the universal property where if there is a bilinear mapping $\phi: A \times B \to C$ for some $R$-module $C$, then there exists a unique linear map $\psi: A \otimes B \to C$ with $\phi = \psi \circ \otimes$.

Assume now that $A$ and $B$ are free $R$-modules of finite rank, say $A = R^a$ and $B = R^b$. Then $A \otimes B$ is again a free $R$-module that can be identifies with he set $R^{a \times b}$ of bidimensional arrays of size $a \times b$ and with coefficients in $R$. The also let $M = R^m$ and $N = R^n$ and take linear maps $\phi: A \to M$ and $\psi : B \to N$.

We compute the tensor product of two linear maps $\phi \otimes \psi$ as follows. Given $x = (x_{i,j}) \in R^{a \times b} = A \otimes B$ we first apply $\psi$ to each of the rows $x_i \in B$. This yields a new array $y = (y_{i, j}) \in R^{a \times n} = A \otimes N$ with $y_i = \psi(x_i)$ for all $i$. We next apply $\phi$ to each of the columns $y_{i, j} \in A$. This yields an array $z = (z_{i, j} \in R^{m \times n} = M \otimes N$ with $z_{\cdot , j} = \phi(y_{\cdot, j})$ for all $j$. We claim that $z = (\phi \circ \psi)(x)$. Indeed, if $x = u \otimes v$, then $y = u \otimes \psi(v)$ and $z = \phi(u) \otimes \psi(v)$ where the claim follows by linearity.

Given $x \in A \otimes B$ the above algorithm allows us to compute $(\phi \otimes \psi) (x)$ in time
\[
    C(\phi \otimes \psi) \leq aC(\psi) + nC(\phi) + O(a n \log \min(a, n) \tx{bit}(R) + m n \log( \min (m, n)\tx{bit}(R))).
\]
where $\tx{bit}(R)$ is the number of bits required to represent an element of $R$ in memory.\\
More generally, given $d$ linear maps $\phi_1: R^{a_1} \to R^{b_1}, \ldots \phi_d: R^{a_d} \to R^{b_d}$ a similar analysis gives us
\[
    C(\phi_1 \otimes \cdots \otimes \phi_d) \leq n_1\cdots n_d \sum^d_{i = 1} \frac{C(\phi_i)}{n_i} + O(n_1\cdots n_d \log (n_1 \cdots n_d) \tx{bit}(R)),
\]
where $n_i = \max(a_i, b_i)$ for $i = 1, \ldots, d$.


\subsection{Multivariate Fourier Transforms}%
\label{sub:multivariate_fourier_transforms}

Continuing with $R$ a commutative ring, let $\mathbf{\omega} = (\omega_1, \ldots, \omega_d) \in R^d$ be such that each $\omega_i$ is a principal $n_i$-th root of unity. As in the univariate case, cyclic polynomials $A \in R[\mathbf{x}]^\circ/(x^n - 1)$ can be evaluated at point of the form ($\omega_1^{i_1}, \ldots, \omega_d^{i_d}$). The DFT of $A$ can then be formulated as 
\[
    \tx{DFT}_{\mathbf{\omega}}(A)_i := A(\omega_1^{i_1}, \ldots, \omega_d^{i_d}), \qquad i \in \N^n
\]
It is not difficult to show that $\tx{DFT}$ provides us with an isomorphism between $R[\mathbf{x}]/(x^n - 1)$ and $R^n$. TODO There is a calculation here where I don't quite understand the notation
In fact, it follows quite naturally from the properties of tensor products that
\[
    \tx{DFT}_{\mathbf{\omega}} = \tx{DFT}_{\omega_1} \otimes \cdots \otimes \tx{DFT}_{\omega_d}
\]
Furthermore it is clear that upon evaluation of a vector $a = a_1 \otimes \cdots \otimes a_d \in \in R^n$ with $a_i \in R^{n_i}$ we have
\[
    \tx{DFT}_{\mathbf{\omega}}(a)_i = A(\omega_1^{i_1}, \ldots, \omega_d^{i_d}) = A_1(\omega_1^{i_1}) \cdots A_d(\omega_d^{i_d})
\]
where $A_k = (a_k)_0 + \cdots + (a_k)_{n_k - 1}x_k^{n_k - 1}$ for each $k$ i.e. we view polynomials as tensors.
