\chapter{Preliminaries}\label{preliminaries}

\section{Rings and stuff}
\label{sec:prelim-rings}

\section{Measuring Complexity}%
\label{sec:Measuring Complexity}


When analysing an algorithm, we want to have some well-defined metric to indicate whether one algorithm is super to the other. There are many ways of measuring complexity but the two main questions we will ask ourselves are

\begin{itemize}
    \item How do we measure the complexity of certain operations (Computation model)
    \item How do compare complexities once we have measured them (notation, theoretical vs practical)
\end{itemize}

There are many other sources of variation in this kind of analysis (most notably linear vs non-linear operations) but we won't go into that here.

\subsection{Complexity models}%
\label{sub:Complexity models}

A computation model is a framework which tells us the operations we are allowed to perform on the data as well as their complexity. 

The two most popular computation models are the Turing machine, and the Random Access machine. We will not give a formal definition here, however we need to know that the main difference for our purposes is that the Turing machine takes into account the size of the data better, that is, as numbers grow bigger, the complexity in the Turing model increases whereas this is not the case in the Random access machine (TODO Check this). The RAM considers operations such as reading, writing and basic arithmetic (addition subtraction) constant time operations as well as in-direct addressing (the use of pointers in modern programming languages). This is quite adequate for most complexity analysis but in this thesis, a large portion of the algorithms will involve coefficients becoming very large and growing with the input to the algorithm. Therefore for the asymptotic section we will use the Turing model to reflect this.

But actually I don't think we use the Turing model all the time so I don't know...

\subsection{Big O-notation}%
\label{sub:Big O-notation}

In this thesis we present a study of algorithms from both a practical and theoretical viewpoint. By \textit{practical complexity} we mean algorithms that are the fastest for a certain range of input parameters. By \textit{theoretical complexity} we mean algorithms that are fastest asymptotically i.e. for large enough inputs. A good example of this distinction are the  Karatsuba, Schonage-Strassen, Harvey-van der Hoeven algorithms. Asymptotically, Harvey-van der Hoeven is the fastest, followed by SS, followed by Karatsuba. However, SS only becomes faster than Karatsuba when the degree of the input polynomials are around $2^{2^{15}}$ (SS wiki page) and H-vdH becomes faster than it at around $2^{1729^{12}}$ bits. (TODO one measurment is in size, one is in bits, should standardize). So even though H-vdH and SS have a much greater theoretical complexity than Karatsuba, it is by far the most practical in normal use cases, and so many computer algebra systems e.g. Maxima only implement Karatsuba'a.

The most common way to talk about the asymptotic complexity of an algorithm is in ``big-O notation''. Informally, we say that an algorithm has is ``$\M{O}(f)$ complexity'' for some function $f$, if it increases (technically it can decrease too e.g. $\M{O}(n^{-1})$) at the same rate as $f$ for suitably large input. 
More formally, let $\M{C}(n)$ be the complexity of the algorithm as measured by some complexity model for inputs $n$ (TODO need to more formally generalise this for multiple inputs). Then the program is "$\M{O}(f)$ complexity" if there exists a $K_1, K_2 > 0$ such that 
\[
    K_1C(n) \leq f(n) \leq K_2C(n)
\]
for all inputs $n$.

For the algorithms we previously stated we have: Karatsuba $\M{O}(n^{\log_2(3)})$, SS $\M{O}(n\log n \log \log n)$, and H-vdH $\M{O}(n \log n)$.

Should I say some basic basic facts like $\M{O}(n^{1 + \epsilon})$ is greater than $\M{O}(n\log n)$ for any $\epsilon > 0$?

\subsection{Recursive formula}%
\label{sub:Recursive forumla}

It is quite common in the study of algorithms to derive recursive algorithms, and so when we are analysing their complexity we may do so with a recursive expression. For instance in the Karatsuba algorithm we will see soon, we get
\[
    \M{C}(n) = \frac{3}{2}C\bb{\frac{n}{2}}
\]
TODO check this.
This terminates when we have $C(1)$ which will happen in $\log_2 n$ steps so we get
\[
    \M{C}(n) = \bb{\frac{3}{2}}^{\log_2 n} = \bb{n}^{\log_2 \frac{3}{2}} = \M{O}(n^{\log_2 3}
\]
