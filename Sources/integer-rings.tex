\chapter{Integer Rings}\label{chp:integer-rings}

In this section, present technique for multiplying polynomials over integer rings. We will formalise the notion of a discrete convolution and establish important theoretical results for the existence of roots of unity in integer rings of certain order. Ad we will see, not all integer rings admit roots of unity, and even if they do, they may have small order e.g. $\Z/2^{2k + 1}\Z$ only admits roots of unity of size $2$. A large portion of this chapter will be devoted to understanding when such a ring admits roots of unity of high order to enable such transformations. As such, the algorithms in this chapter will not present any new theoretical bound on multiplication; the aim is to create algorithms that are practically efficient for moderate input sizes.

% There are several common use cases for the use of polynomial multiplication in integer rings; each puts different constraints of the types of rings we use to it is important to understand the difference. Branching off the work in previous chapters we can use integer rings to avoiding the loss of precision that comes from considering $\Z[x]$ as a subring of $\C[x]$ and performing a complex FFT. Here we use the Chinese Remainder theorem to map the polynomials in $\Z[x]$ into several polynomials with coefficients in integer rings to which we can then apply the FFT algorithm.

Integer rings are commonly used to control the size of the coefficients throughout the multiplication process for polynomials in $\Z[x]$. We can first transform the polynomials in $\Z[x]$ into several polynomials in integer rings that admit fast FFTs, and then reconstruct the result in $\Z[x]$ via the Chinese Remainder Theorem. This is a very popular choice for large parallel computing as it is easily implemented on a Graphics Processes Unit (GPU) \cite{gpu-mult} \cite{crt-parallel-mul} \cite{gpu-kepler-architecture}.

The techniques in this chapter are commonly used throughout cryptography and signal processing. These applications offer a large amount of flexibility over the choice of the integer ring, and so Section \ref{sec:practically-efficient-ntt} discusses criteria for choosing rings which admit efficient arithmetic.

It is important to differentiate the use cases as each imposes a different set of restrictions on the ring, and subsequently, the optimisations we can apply. The most favourable to choose are those that offer efficient arithmetic in common computer architectures. Though we also that the methods in this chapter may be supplemented with a fast division scheme such as Barret Reduction \cite{barret} which improves the efficiency of divisions in the integers rings by replacing them with multiplications. This is often much more efficient since the regular division operation in most modern CPUs is not as efficient as multiplications \cite{instruction-times}.

Bear in mind, that one can still use the algorithms from Chapter \ref{chp:classical} and Chapter \ref{chp:eval-interp} if we first use Kronecker substitution to transform the inputs from $\Z/N\Z[x]$ to a problem in $\Z[x]$. However, it is often more efficient to perform calculations directly in $\Z/N\Z$ since the elements are always bounded and so arithmetic operations as executed in a time proportional to $N$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%% Finished: N %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Convolutions}

% Check it is the unique function
Convolutions are fundamental in the field Fourier analysis as the DFT is the unique function that has the \emph{convolution property}. We will formulate this property and show how polynomial multiplication can viewed to provide a second intuition as to how the FFT can be used to multiply polynomials. Though we will show polynomial multiplication and convolutions to be equivalent problems, the language of convolutions is often more apt in the context of signal processing and finite automata where the techniques in this section are commonly applied.

\begin{definition}[Discrete Convolution]
    Let $K$ be a commutative ring, and $u, v \in K^n$. The \textit{convolution} of $u$ and $v$ is defined as
    \[
        (u \ast v)_k = \sum^{n-1}_{i=0} u_i v_{k-i} \in K^n,
    \]
    where $u_{k-i}$ is understood to mean $u_{k-i \mod n}$.
\end{definition}

\begin{proposition}\label{prop:poly-conv-iso}
    Let $K$ be a commutative ring. Then for any $n \in \N$, we have the isomorphism of rings
    \[
        \bb{\frac{K[x]}{x^n - 1}, \times} \cong (K^n, \ast).
    \]
\end{proposition}

\begin{proof}
    The map $K[x]/(x^n - 1) \to K^n$ is given by associating the coefficients of a polynomial with its corresponding vector. That is
    \begin{equation}\label{eq:poly-to-vec}
        \sum_{i=0}^{n-1} f_i x^i \mapsto (f_0, \ldots, f_{n-1}).
    \end{equation}
    This is clearly a bijection.

    To see that this is an isomorphism, consider two polynomials $f, g \in K[x]/(x^n - 1)$, given by $f(x) = \sum_{i=0}^{n-1} f_i x^i$ and $g(x) = \sum_{i=0}^{n-1} g_i x^i$. Then
    \begin{align*}
        f(x)g(x) = \sum^{2n-1}_{k=0} \bb{\sum_{i + j = k}f_ig_j} x^k
        &= \sum^{n-1}_{k=0} \bb{\sum_{i + j = k \mod n}f_jg_i} x^k\\
        &= \sum^{n-1}_{k=0} \bb{\sum_j f_jg_{k-j}} x^k \mod (x^n - 1).
    \end{align*}
    Hence the coefficients of the polynomial are exactly the those given by the convolution of $f$ and $g$, thus the map \ref{eq:poly-to-vec} induces the isomorphism in the proposition.
\end{proof}

% TODO could I maybe not word this as a corollary
\begin{corollary}\label{cor:equiv-poly-conv}
    For $n \in \N$, Polynomial multiplication in $K[x]$ and convolutions in $K^n/(x^n - 1)$ for any $n \in \N$ are equivalent problems.
\end{corollary}

\begin{proof}
    To multiply polynomials using a convolution, let $f, g \in K[x]$ and $n = \deg f + \deg g + 1$. Then since $(K[x]/(u^n - 1), \times) \cong (K^n, \ast)$, we may use a convolution to evaluate $h = fg \in K[x]/(x^n -1)$. Since $\deg f, \deg g, \deg h < n$, we can recover the true answer $h \in K[x]$.

    To use multiplication to solve convolutions, we convert the vectors $f^\prime, g^\prime \in K^n$ into polynomials $f, g \in K[x]$. Then multiply as usual and apply the substitution $x^n = 1$. This requires $\M{O}(n)$ ring operations, and since we know that multiplication has at least linear complexity, this does not change the total asymptotic complexity.
\end{proof}

\begin{definition}[Convolution Property]\label{def:convolution-property}
    Let $u$ and $v$ be two sequences of length $n$ in a ring $K$. Then let $\M{F}_n$ and $\M{F}_n^{-1}$ denote the discrete Fourier transform and its inverse. Then
    \[
        u \ast v = \M{F}_n^{-1}(\M{F}_n u \cdot \M{F}_n v)
    \]
    where $\cdot$ represented element-wise multiplication of the two sequences.
\end{definition}

% Did I actually give that in that chapter?
This can be proved by applying Corollary \ref{cor:equiv-poly-conv} and the analogous result for polynomials in Chapter \ref{chp:eval-interp}.

We mentioned previously that padding the DFT with zeros changes the underlying signal and may lead to an incorrect result in the general case; Bluestein's algorithm allows us to overcome this issue by expressing a DFT as a convolution.

% TODO this needs to be clearer in terms of the complexity.
\begin{proposition}[Bluestein's Algorithm]
    Let $\M{C}_F(n)$ denote the number of ring operations required to compute a DFT, and $\M{M}_K(n)$ denote the number of ring operations to compute an $n$-dimensional convolution in $K^n$. Then
    \[
        \M{C}_F(n) \le \M{M}_K(n) + \M{O}(n).
    \]
\end{proposition}

\begin{proof}
    Recall the Fourier coefficients of the DFT of a sequence $u \in K^n$ are given as
    \[
        (\M{F}_n u)_k = \sum^{N-1}_{j=0} u_j\omega_n^{-jk}
    \]
    where $\omega$ is an $N^{\tx{th}}$ root of unity.

    Using the identity $jk = \frac{1}{2}(j^2 + k^2 - (j - k)^2))$ we can rewrite the formula as
    \[
        (\M{F}_n u)_k = \omega_N^{k^2/2} \sum^{N-1}_{j=0} (a_j \omega_N^{j^2/2}) \omega_n^{(j - k)^2/2}.
    \]
    If we then take $f = (u_n \omega_N^{j^2/2})_{j=0}^{N-1}$ and $g = (\omega_N^{j^2/2})_{j=0}^{N-1}$ we have the formula
    \begin{equation}\label{eq:yeet}
        (\M{F}_n u)_k = g_k \cdot \bb{\sum^{N-1}_{j=0} f_j g_{k-j}} = g_k \cdot (f \ast g)_k.
    \end{equation}
    Thus we can use the convolution to evaluate the DFT. Calculating $f$ and $g$ requires $\M{O}(n)$ ring operations, and after calculating the convolution we must multiply the result elements-wise, which can also be done in $\M{O}(n)$ ring operations. Therefore, calculating \eqref{eq:yeet} gives
    \[
        \M{C}_F(n) \le \M{M}_K(n) + \M{O}(n).
    \]
\end{proof}

Therefore since element-wise multiplications is $O(n)$, we can see that the problem of calculating convolutions has the same complexity as computing the DFT.

It may seem counterintuitive as we would then use the DFT to evaluate the convolution. However, the fundamental difference is that when evaluating a convolution, we may choose an DFT of any transform length greater than $N - 1$, which we are unable to do with the original DFT. Thus we can use Bluestein's algorithm\cite{bluestein} to use more efficient FFT algorithms for specific transform sizes e.g. highly composite sizes (FFT), prime sizes (Rader's Transform, Definition \ref{thm:rader-transform}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%% Finished: N %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Number Theoretic Transform}
\label{sec:ntt}


Consider the problem of evaluating the DFT of a sequence of $n$ elements of the integer ring $\Z/N\Z$ for some $N \in \N_{> 0}$. Recall that the FFT may be applied in any field which admits roots of unity, and where $2$ is invertible. We can always use the Sch\"{o}nage and Strassen algorithm when $N$ is odd, however it may only outperform classical algorithms such as Karatsuba's at exceedingly large degree sizes. If $N$ is prime, we can use Rader's algorithms to reorder the inputs as a convolution of length $N-1$. Thus if $N - 1$ is highly composite, this enables use to apply FFT-based algorithms.

% TODO Need to talk more about the NTT here
The Number Theoretic Transform (NTT) is a generalisation of the Fast Fourier Transform for integer rings.
% Though fundamentally nothing is different

\subsection{Rader's Algorithm}
\label{subsec:rt}

% TODO Martin recommends rephrasing the last line
Rader's algorithm is a method to evaluate the DFT of prime size $N$ by expressing it as a cyclic convolution of size $N - 1$. This is similar to Bluestein's algorithm but is much more efficient in practice since we don't need to calculate any additional sequences or vector products. This is not as efficient for arbitrary finite fields, but in many applications such as cryptography, we may choose to perform our calculations over fields where $N - 1$ is highly composite to facilitate an efficient NTT. This is a common trick used in industry software such as the FFTW library which uses Rader's algorithm to gain a $2$x speedup in certain situations \cite{fftw}.

\begin{definition}[Rader's Algorthm]\label{thm:rader-transform}
    Let $p$ be prime, then there exists a primitive element of $\F_p$, that is, a $g \in \F_p$ such that $(g^i)_{i=1}^{N-1}$ is a permutation of $1, \ldots, N-1$. Then by applying the map $i \mapsto g^i, k \mapsto g^k$ the DFT $\M{F}u$ of $u \in \F_p^n$ can be realised as a convolution of the two vectors $(u_{g^i})_{i=0}^{n-1}$ and $\omega_N^{g^i}$,
    \begin{align*}
        A_k - a_0 = \sum^{n-1}_{i=1} a_i \omega_N^{ik} \qquad &\mapsto \qquad A_{g^k} - a_0 = \sum^{n-1}_{i=1} a_{g^i}\omega_n^{g^{i+k}}
    \end{align*}
\end{definition}

If $N - 1$ is highly composite, we can apply the standard FFT algorithms to evaluate the sum efficiently. Therefore the ideal case is when $N = 2^k + 1$ for some $k$ and where $N$ is prime. In the special case that $n$ is also a power of two, $N$ is a \emph{Fermat number}. We will revisit these in Section \ref{sec:practically-efficient-ntt} as they are especially convenient when performing arithmetic operations.

\subsection{Existence of NTT}%
\label{sub:Existence of NTT}

Now we will establish theoretical results for the existence of roots of unity in integers rings.
In this section we will primarily follow the treatment in \cite{intro-to-fmt}.

\begin{theorem}\label{thm:fmt-transform-length}

    There exists a root of unity of order $n$ the ring of integers modulo an integer $N$ if and only if $n$ and $N$ are relatively prime and $n$ divides $\gcd(p_1 - 1, \ldots, p_k - 1)$ where $p_1, \cdots, p_k$ are the distinct prime divisors of $N$.
\end{theorem}

% TODO check the first bit of this.
\begin{proof}
    Suppose $\alpha$ is a root of unity of order $n$, that is $\alpha^n \equiv 1 \mod N$. Then via the Chinese Remainder Theorem we must also have $\alpha^n \equiv 1 \mod p_i^{r_i}$ for all $i$ and hence $\alpha^n \equiv 1 \mod p_i$. Since $n$ and $N$ are coprime, we have that $n$ and $p_i^{r_i}$ are coprime, and so by Euler's Theorem, $n$ must divide the Euler totient function $\varphi(p_i^{r_i}(p_i - 1)$.

    Since $n$ and $N$ are relatively prime, $n \nmid p_i^{\alpha_i}$ therefore $n \mid p_i - 1$ for all $1 \le i \le k$. Thus $n | \gcd\{p_1 - 1, \ldots, p_k - 1\}$.

    \medskip

    To show existence, note that if $n | (p_i - 1)$, then there exists integers of order $n$ in $\Z/p_i^{\alpha_i}$. Applying the Chinese Remainder Theorem on these elements in the reverse direction, we can recover an element $\alpha \in \Z/N$ which has order $n$.

    \medskip

    Since $N$ and $p_i$ are relatively prime, $n^{-1}$ exists in $\Z/N$. Therefore the conditions of Theorem \ref{thm:fft} are satisfied.
\end{proof}

Note that the transforms in the subfields can recursively apply Rader's Algorithm if the exponent of the prime divisor is one.

(TODO mention the standard techniques for finding roots of unity in these rings)


\section{Practically Efficient NTTs}%
\label{sec:practically-efficient-ntt}

We now look at finding a suitable integer $N$ such that the NTT in $\Z / N\Z$ admits an efficient implementation. In this doctoral thesis on the NTT implementations for microprocessors \cite{ntt-thesis}, Martin outlined several requirement for efficient implementations of the NTT. The first three concerning the existence of a transform are summarised by Theorem \ref{thm:fmt-transform-length}, followed by
\begin{itemize}
    \item The transform length $N$ should be highly composite to facilitate fast transform algorithms.
    \item Multiplication by the roots of unity must have a simple binary representation to facilitate fast multiplications.
    \item $N$ has a simple binary representation to facilitate fast divisions.
\end{itemize}

We note that if the last point does not hold then we may look at using Montgomery Multiplication or Barret Reduction to covert divisors into multiplications \cite{barret}.

% TODO from Intro-to-FMT. Should change
Taking $N$ to be a power of two would be the canonical choice as it admits the fastest arithmetic on modern computers. However, Theorem \ref{thm:fmt-transform-length} tells us the maximum transform length would be $1$ in that case; thus, it is completely unsuitable for an NTT. The next class of numbers we might consider are those of the form $2^k - 1$ for some $k \in \N$. Numbers of this form are known as \textit{Mersenne numbers}, and their corresponding transforms are Mersenne Number Transforms (MNT). Mersenne Numbers admit highly efficient transforms though we will not discuss them here, and refer the reader to the discussion in \cite{mersenne} \cite{mersenne-recent}.

% TODO Prove this
The next case we consider numbers of the form $2^k + 1$. When $k$ itself is a power of two, it has less small divisors, e.g. if $k$ is odd then $3$ divides $2^k + 1$, hence the maximum transform length is $2$. Numbers of the form $2^{2^\ell} + 1$ for $l \in \N$ are known as Fermat Numbers, and their corresponding transforms are Fermat Number Transforms (FMT).

% TODO show the stuff here
The Fermat Numbers up to $\ell = 4$ are all primes, and therefore can be calculated very efficiently using the Rader Transform (Theorem \ref{thm:rader-transform}). It can then be shown \cite{intro-to-fmt} that all the factors of Fermat numbers are of the form $c2^{\ell + 2} + 1$ for $c \in \N$. Therefore by Theorem \ref{thm:fmt-transform-length} the maximum transform length is $2^{\ell + 2}$. It can also be shown that a root of such order is $2^{2^{t-2}}(2^{2^{t-1}} - 1)$.
(I am going to include a small section here proving this)

\medskip

When this field was first pioneered in the 1970s, a significant drawback of Fermat Number Transforms is that they are not as memory efficient as other candidates, as they require $k + 1$ bits of memory to hold only a little more than $2^k$ values. However this is not a real concern for modern computers. Agarwal and Burrus (Section VI \cite{intro-to-fmt}) suggested allowing the last number to overflow and rounding it to $\minus 1$, $0$ or $-2$ since there is a low probability ($2^{-k}$ chance) that the forgotten number will arise. This technique was originally suggested in the context of Fourier Transforms for fast signal processing, and so such an error is likely to be insignificant in those contexts. However, it is unsuitable for our purposes where we are trying to obtain the true solutions.

% TODO mention the other things here
