% My study of Basis mostly came from https://arxiv.org/ftp/arxiv/papers/1304/1304.0420.pdf
\chapter{Integer Rings}\label{chp:integer-rings}

(TODO Mention that the transformation from convolution to multiplication is Bluestein's chirp transform, and the transformation from multiplication to convolution is the FFT)

In this section, we will look at performing polynomial multiplication over integer rings. One of the first things that we will show is that some integer rings support FFTs, though only with certain transform lengths. A large portion of this chapter will be devoted to understanding when such a ring admits roots of unity of high order to enable such transformations.

There are several common use cases for the use of polynomial multiplication in integer rings; each puts different constraints of the types of rings we use to it is important to understand the difference. Branching off the work in previous chapters we can use integer rings to avoiding the loss of precision that comes from considering $\Z[x]$ as a subring of $\C[x]$ and performing a complex FFT. Here we use the Chinese Remainder theorem to map the polynomials in $\Z[x]$ into several polynomials with coefficients in integer rings to which we can then apply the FFT algorithm. 

This is also often used to control the size of the coefficients throughout the process, we can multiply the polynomials via an FFT in several finite fields of relatively small characteristic, and then reconstruct the result in $\Z[x]$ through the Chinese Remainder Theorem (CRT). This is a very popular choice for large parallel computing as it is easily implemented on a Graphics Processes Unit (GPU) \cite{gpu-mult} \cite{crt-parallel-mult} \cite{gpu-kepler-architecture}.

Computer hardware optimisations and creating \emph{trapdoor functions} for cryptographic proposes. This case offers the most flexibility over the choice of the divisor $N$, allowing us to choose divisors which are very efficient to perform arithmetic in using a computer.

It is important to differentiate the use cases as each imposes a different set of restrictions on the divisor, and subsequently, the optimisations we can apply. The most favourable to choose are those that offer efficient arithmetic in common computer architecture. Namely, divisors $N$ whose binary representation has few ones. Though throughout all these we can also use Barret Reduction \cite{barret} to improve the efficiency of divisions in the integers rings by replacing them with multiplications. This is often much more efficient since the regular division operation in most modern CPUs is not particularly efficient as multiplications \cite{instruction-times}.

Remember that one can still use the Karatsuba/Toom-Cook algorithms here as well as the Sch\"{o}nage-Strassen algorithm if we use Kronecker substitution to transform the inputs from $\Z/N[x]$ to a problem in $\Z[x]$. However, it is often more efficient to perform calculations directly in $\Z/N$ since the elements are always bounded and so arithmetic operations as executed in a time proportional to $N$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%% Finished: N %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\subsection{Convolutions}

(TODO Reword this)

Convolutions are important in the field Fourier analysis as the DFT is the unique function that has the \emph{convolution property} that allows for efficient computations (TODO cite). We will introduce this property and show how polynomial multiplication can viewed as a convolution, thus giving a second intuition as to how the FFT can be used to multiply polynomials. The language of convolutions is often more apt in the context of signal processing and finite automata where the techniques in this section are commonly applied.

\begin{definition}[Discrete Convolution]
    Let $(x_i)_{i=0}^{n-1}, (y_i)_{i=0}^{n-1} \in K^n$ be two sequences in a ring $K$. The convolution of $x$ and $y$ is defined as
    \[
        (x \ast y)_k = \sum^{n-1}_{i=0} x_i y_{k-i} \in K^n
    \]
    where $y_{k-i}$ is understood to mean $y_{k-i \mod n}$.
\end{definition}

\begin{proposition}
    Let $K$ be a commutative ring. Then for any $n \in \N$, we have the isomorphism of rings
    \[
        (\frac{K[x]}{x^n - 1}, \cdot) \cong (K^n, \ast)
    \]
\end{proposition}

\begin{proof}
    The map $K[x]/(x^n - 1) \to K^n$ is given by associating the coefficients of a polynomial with its corresponding vector. That is
    \[
        \sum_{i=0}^{n-1} f_i x^i \mapsto (f_0, \ldots, f_{n-1})
    \]
    This is clearly a bijection. 

    To see that this is an isomorphism, consider two polynomials $f, g \in K[x]/(x^n - 1)$, given by $f(x) = \sum_{i=0}^{n-1} f_i x^i$ and $g(x) = \sum_{i=0}^{n-1} g_i x^i$. Then 
    \[
        f(x)g(x) = \sum^{2n}_{k=0} \bb{\sum_{i + j = k}f_ig_j} x^k = \sum^n_{k=0} \bb{\sum_{i + j = k \mod n}f_jg_i} x^k = \sum^n_{k=0} \bb{\sum_j f_jg_{k-j}} x^k \mod (x^n - 2)
    \]
    Hence the coefficients of the polynomial are exactly the those given by the convolution of $f$ and $g$.
\end{proof}

% TODO could I maybe not word this as a corollary
\begin{corollary}
    Polynomial multiplication in $K[x]$ and convolutions in $K^n$ for any $n \in \N$ are equivalent problems.
\end{corollary}

\begin{proof}
    To multiply polynomials using a convolution, let $f, g \in K[x]$ and $n = \deg f + \deg g + 1$. Then since $(K[x]/(x^n - 1), \cdot) \cong (K^n, \ast)$, we can use a convolution to evaluate $h = fg \in K[x]/(x^n -1)$. Since $\deg f, \deg g, \deg h < n$, we can recover the true answer $h \in K[x]$.

    To use multiplication to solve convolutions, we make convert the sequences $f^\prime, g^\prime \in K^n$ into polynomials $f, g \in K[x]$. Then multiply as usual and apply the substitution $x^n = 1$. This then requires $\M{O}(n)$ additions.
\end{proof}

The convolution property can then be stated as

\begin{definition}[Convolution Property]\label{def:convolution-property}
    Let $x$ and $y$ be two sequences of length $n$ in a ring $K$. Then let $\tx{DFT}$ and $\tx{DFT}^{-1}$ denote the discrete Fourier transform and its inverse. Then
    \[
        x \ast y = \tx{DFT}^{-1}(\tx{DFT}(x) \cdot \tx{DFT}(y))
    \]
    where $\cdot$ represented element-wise multiplication of the two sequences.
\end{definition}


\begin{proposition}[Bluestein's Algorithm]
    We can use convolutions to evaluate the DFT using Bluestein's algorithm.
\end{proposition}

\begin{proof}
    Recall the Fourier coefficients of the DFT of a sequence $(a_0, \ldots, a_{n-1})$ are given as
    \[
        X_k = \sum^{N-1}_{j=0} a_j\omega_n^{-jk}
    \]
    where $\omega$ is an $N^{\tx{th}}$ root of unity.
    
    Using the identity $jk = \frac{j^2 + k^2 - (j - k)^2)}{2}$ we can rewrite the formula as
    \[
        X_k = \omega_N^{k^2/2} \sum^{N-1}_{j=0} (a_j \omega_N^{j^2/2}) \omega_n^{(j - k)^2/2}
    \]
    If we then take $f = (a_n \omega_N^{j^2/2})_{j=0}^{N-1}$ and $g = (\omega_N^{j^2/2})_{j=0}^{N-1}$ we have the formula
    \[
        X_k = g_k \cdot (\sum^{N-1}_{j=0} f_j g_{k-j} = g_k \cdot (f \ast g)_k
    \]
    Thus we can use the convolution to evaluate the DFT.
\end{proof}

This may seem useless as we would then simply use the DFT to evaluate the convolution. However, the fundamental difference is that when choosing to evaluate a convolution, we may choose an DFT of any transform length greater than $N - 1$. However we cannot simply pad the original DFT with zeros as that would change the signal. Thus we can use Bluestein's algorithm\cite{bluestein} to use more efficient FFT algorithms for specific transform sizes e.g. highly composite (FFT), prime (Rader's Transform, Definition \ref{thm:rader-transform}).

% TODO fix this 

In the previous chapter, we saw this exact procedure but under the evaluation-interpolation label, where the two inner DFTs are the evaluations and the final $\tx{DFT}^{-1}$ is the interpolation.

Therefore since element-wise multiplications is $O(n)$, we can see that the problem of calculating convolutions has the same complexity as computing the DFT (TODO the inverse DFT has the same complexity as the DFT, don't know if I really need to explain that).

Before we can give an overview of the main algorithm, we first need to explain how to transform a multiplication problem in $\Z[x]$ into a convolution in $\otimes_{i=1}^{d} \C^{s_i}$.\\
Note the isomorphism between the two rings arises by associating each element in the left hand side with its coefficient vector, this gives
\begin{equation}\label{eq:mult-to-convolution}
    \bb{\frac{\C[x_1, \ldots, x_d]}{x_1^{s_1} - 1, \ldots, x_d^{s_d} - 1}, \times} \cong (\otimes_{i=1}^d \C^{s_i}, \ast).
\end{equation}
We begin by proving a lemma to allow us to transform a DFT into a multidimensional DFT.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%% Finished: N %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Number Theoretic Transform}
\label{sec:ntt}


Consider the problem of evaluating the DFT of a sequence of $n$ elements of the integer ring $\Z/N$ for some $N \in \N_{\ge 0}$. Recall that the FFT is applicable in any field which has roots of unity, and where $2$ is invertible. However, when $N$ is prime, we can can perform an algebraic manipulation of the inputs to re-express it as a convolution of length $N-1$ using the Rader Transform.

The Number Theoretic Transform (NTT) is a generalisation of the Fast Fourier Transform for integer rings.

\subsection{Rader's Algorithm}
\label{subsec:rt}

% TODO polish this
Rader's algorithm is a method to evaluate the DFT of prime size $N$ be expressing it as a cyclic convolution of size $N - 1$. This is different to Bluestein's algorithm which expresses it as a transform of length $N$. This is not as efficient for arbitrary finite fields, but in many applications such as cryptography, we may choose the fields to work in. Hence we will choose a fields with prime characteristic and where $N - 1$ is highly composite to enable an FFT. FFTW is an industry implementation of the FFT which uses Rader's algorithm to gain a $2$x speedup in certain cases \cite{fftw}.

\begin{definition}\label{thm:rader-transform}
    Let $n$ be prime, then there exists a primitive element of $\Z/n$, that is, a $g \in GF(N)$ such that $\{g^i\}_{i=1}^{N-1}$ is a permutation of $1, \ldots, N-1$. Then the DFT under this permutation as can be realised as a convolution of the two sequences $\{a_{g^i}\}_{i=1}^{n-1}$ and $\omega_N^{g^i}$.
    \begin{align*}
        A_k - a_0 = \sum^{n-1}_{i=1} a_i \omega_N^{ik} \qquad &\mapsto \qquad A_{g^k} - a_0 = \sum^{n-1}_{i=1} a_{g^i}\omega_n^{g^{i+k}}\\
        \tx{ via } i \mapsto g^i&, k \mapsto g^k
    \end{align*}
\end{definition}

If $N - 1$ is highly composite, we can apply the standard FFT algorithms to evaluate the sum efficiently. Therefore the ideal case is when $N = 2^n + 1$ for some $n$ and where $N$ is prime. In the special case that $n$ is also a power of two, these are known as \emph{Fermat numbers}. We will revisit these in Section \ref{sec:hardware-efficient-ntt} as they are especially convenient when performing arithmetic operations.

\subsection{Existence of NTT}%
\label{sub:Existence of NTT}

In this section we will primarily follow the treatment in \cite{intro-to-fmt}.

\begin{theorem}\label{thm:fmt-transform-length}
    An $n \times n$ transform having the cyclic convolution property in the ring of integers modulo an integer $N$ exists if and only if $n$ and $N$ are relatively prime and $n$ divides $\gcd(p_1 - 1, \ldots, p_k - 1)$ where $p_1, \cdots, p_k$ are the distinct prime divisors of $N$.
\end{theorem}

\begin{proof}
    If there exists an element $\alpha$ of order $n$ in $\Z/N$, then it follows from the Chinese Remainder Theorem that there exists elements of order $N$ in the fields $\Z/p_1^{\alpha_1}, \cdots, \Z/p_k^{\alpha_k}$. (TODO doesn't only require that there exists an element whose order merely divides $N$ in these fields?).\\
    Therefore this implies that $n$ must divide the Euler totient function $\varphi(p_i^{\alpha_i}) = p_i^{\alpha_i}(p_i - 1)$. Since $n$ and $N$ are relatively prime, $n \nmid p_i^{\alpha_i}$ therefore $n \mid p_i - 1$ for all $1 \le i \le k$. Thus $n | \gcd\{p_1 - 1, \ldots, p_k - 1\}$.

    \medskip

    To show existence, note that if $n | (p_i - 1)$, then there exists integers of order $n$ in $\Z/p_i^{\alpha_i}$. Applying the Chinese Remainder Theorem on these elements in the reverse direction, we can recover an element $\alpha \in \Z/N$ which has order $n$.

    \medskip

    Since $N$ and $p_i$ are relatively prime, $n^{-1}$ exists in $\Z/N$. Therefore the conditions of Theorem \ref{thm:fft} are satisfied.
\end{proof}

(TODO mention the standard techniques for finding roots of unity in these rings)

Notice that the transforms in the subfields can use Rader's Algorithm if the exponent of the prime divisor is one.


\section{Hardware Efficient NTTs}%
\label{sec:hardware-efficient-ntt}

We now look at finding a suitable $N$ such that the NTT in $\Z / N$ admits an efficient implementation. As outlined in \cite{intro-to-fmt} this requirement can be formulated into three criteria:
\begin{itemize}
    \item The transform length $N$ is highly composite to facilitate FFT-like algorithms.
    \item Multiplication by the roots of unity is efficient to implement.
    \item Division by $N$ is efficient.
\end{itemize}

% TODO from Intro-to-FMT. Should change
Taking $N$ to be a power of two would be the canonical choice as it admits the fastest arithmetic on modern computers. However, Theorem \ref{thm:fmt-transform-length} tells us the maximum transform length would be $1$ in that case; thus, it is unsuitable for an NTT. The next class of numbers we might consider are those of the form $2^k - 1$ for some $k \in \N$. Numbers of this form are known as \textit{Mersenne numbers}, and their corresponding transforms are Mersenne Number Transforms (MNT). Mersenne Numbers admit highly efficient transforms though we will not discuss them here. We refer the reader to \cite{mersenne} \cite{mersenne-recent}.

The next case we consider numbers of the form $2^k + 1$. When $k$ itself is a power of two, it has less small divisors, e.g. if $k$ is odd then $3$ divides $2^k + 1$, hence the maximum transform length is $2$. Numbers of the form $2^{2^\ell} + 1$ for $l \in \N$ are known as Fermat Numbers, and their corresponding transforms are Fermat Number Transforms (FMT).

The Fermat Numbers up to $\ell = 4$ are all primes, and therefore can be calculated very efficiently using the Rader Transform (Theorem \ref{thm:rader-transform}). It can then be shown (TODO cite) that all the factors of Fermat numbers are of the form $c2^{\ell + 2} + 1$ for $c \in \N$. Therefore by Theorem \ref{thm:fmt-transform-length} the maximum transform length is $2^{\ell + 2}$. It can also be shown that a root of such order is $2^{2^{t-2}}(2^{2^{t-1}} - 1)$. 

\medskip

When these field was first pioneered in the 1970s, a significant drawback of Fermat Numbers is that they are not as memory efficient as some other choices, as they hold $2^k + 1$ values and so require $k + 1$ bits of memory each. However this is not a real concern for modern computers. Agarwal and Burrus (Section VI \cite{intro-to-fmt}) suggested allowing the last number to overflow and rounding it to a $-1$, $0$ or $-2$ because there is a low probability ($2^{-k}$ chance) that the forgotten number will arise. This technique was originally suggested in the context of Fourier Transforms for fast signal processing, and so such an error is likely to be insignificant in those contexts. However, it is unsuitable for our purposes where we require correct solutions.
