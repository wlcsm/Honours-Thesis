\chapter{Introduction}\label{introduction}
\addcontentsline{toc}{chapter}{Introduction}


Polynomial multiplication is a fundamental problem in computational mathematics. Not only does it have numerous practical applications, but it can be generalised to a broader class of problems such as integers multiplication, calculating the Discrete Fourier Transform and evaluating convolutions. Despite being widely used, the first significant algorithmic advancement was in 1962 by Karatsuba \cite{karatsuba} who presented his discovery a week after attending a seminar by Kolmogorov who conjectured that no such improvement was possible. This development, combined with the increasing demand for efficient digital processing, quickly saw a pique of interest in the mathematical community with several subsequent multiplication algorithms being produced shortly after. Many of the algorithms developed in this 10 year period such as the Toom-Cook algorithm, Rader's trick, and FFT based algorithms, are still popular today. As the computational sciences sought to understand increasingly complex systems, there was a need to multiply larger polynomials for fundamental problems such as solving systems of polynomial equations, computing Gr\"{o}bner bases, and evaluating convolutions.

\medskip

The focus of this thesis is on studying the most significant advancements in the field, starting from the first improvement over the schoolbook method by Karatsuba, and ending with the recent improvement by Harvey and van der Hoeven \cite{nlogn}. There are many variables that can affect the efficiency and validity of polynomial multiplication algorithms such as the number of indeterminates, the coefficient algebra, and the number of non-zero terms. The two variable of most interest to us are sparsity and the coefficient algebra of the polynomials. Analysis of the algorithms will be performed within two different contexts, namely their practical performance for a suitable range of inputs, and their asymptotic nature as the size of the inputs grows increasingly large. Along with this thesis we have implemented several of these algorithms as part of our nPoly polynomial library which can be found at \url{https://github.com/willcsm/nPoly}. We provide a commentary on key implementation details on these algorithms and have conducted empirical tests to support the theoretical results.

Due to their simplicity and generality, most computer algebra systems still rely on old multiplication schemes which work across a broad range of inputs at the cost of performance. A minor goal of this thesis is to analyse the practical complexity of such methods to develop a heuristic for computer algebra systems to select the most efficient algorithm for the given inputs.

\section{Structure of Thesis}
\label{sec:Structure-of-Thesis}

Before we can begin analysing algorithms, we first need to formalise the computational model our algorithms are executed in. Since there is no ubiquitous model, Chapter \ref{chp:preliminaries} provides a mathematical refresher and summary of necessary complexity-theoretic definitions and notation. In particular, we present a brief introduction to the two computation models we will be using throughout this thesis; namely the multi-tape Turing machine and an adaptation of the Random Access Machine (RAM) for rings.

Chapter \ref{chp:classical} gives an overview of several important classical algorithms. These are currently the most widely implemented algorithms due to their simplicity, generality, and efficiency for polynomials of small to moderate degree sizes. Popular computer algebra systems such as Macaulay2 \cite{macaulay2-polynomial}, Maxima \cite{maxima-karatsuba}, NTL \cite{ntl}, and Magma \cite{magma} all use at least one of these algorithms.

Chapter \ref{chp:eval-interp} looks at the \emph{evaluation-interpolation strategy} for multiplying polynomials, and shows how algorithms such as Karatsuba's from Chapter \ref{chp:classical} can be re-expressed in this framework. We will provide an introduction to the Discrete Fourier Transform (DFT) and show how it can be used to evaluate convolutions, followed by a theorem showing how we may apply the Cooley-Tukey Fast Fourier Transform (FFT) to multiply polynomials in $O(n \log n)$ ring operations, which provides the foundations for the popular class of FFT-based algorithms. We finish with a generalisation of Sch\"{o}nage and Strassen's integer multiplication algorithm for polynomials over commutative rings. The FFT-based approach marks the beginning of the more exotic algorithms which go beyond the coefficient-agnostic transformations in Chapter \ref{chp:classical}, and which are often only used in specialised applications where the degree of the polynomials are large.

Chapter \ref{chp:integer-rings} looks at algorithms for polynomials in integer rings. Multiplications in this ring circumvents the main shortcoming associated with algebras from previous sections, namely the increasing computational cost of ring operations in unbounded algebras (e.g. $\R$, $\C$, $\Z$). This enable our algorithms to be optimised an improved practical complexity. This area is of particular interest when computing polynomials of large degree in $\Z[x]$ \cite{crt-parallel-mul}\cite{crt-mul-gpu}, and other areas optimised for speed such as cryptography and signal processing. Efficiency is achieved by mapping our inputs into appropriately chosen rings which admit efficient Number Theoretic Transforms (NTT); a generalisation of the FFT for integer rings.

Chapter \ref{chp:asymptotic} looks at the most recent advancement in the theoretical complexity of polynomial multiplication, that is, Harvey and var der Hoeven's $O(n \log n)$ integer multiplication algorithm. Despite the algorithm \cite{nlogn} being formulated for integers, we will demonstrate how this result can be directly applied to the problem of polynomial multiplication using the techniques from Chapter \ref{chp:classical}. The theoretical bound is achieved by constructing a multi-dimensional convolution that controls the error in its finite precision arithmetic. We will also present another algorithm by Harvey and van der Hoeven that achieves the same bound but is conditional on an unproven hypothesis. It takes a more intuitive approach which naturally generalises the result for finite fields.

Chapter \ref{chp:implementation} will introduce an algorithm for sparse polynomial multiplication. This is particularly useful in modern computer algebra applications and situations involving multivariate polynomials. We also present an empirical analysis of the performance of several of the algorithms in this thesis in our nPoly polynomial library\cite{npoly}.
